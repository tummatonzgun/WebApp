import pandas as pd
import numpy as np
import os
import sys
from datetime import datetime

def apply_zscore(df):
    """‡∏ï‡∏±‡∏î outliers ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ Z-Score (¬±3 standard deviations)"""
    col_map = {col.lower(): col for col in df.columns}
    if 'uph' not in col_map:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå UPH ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    uph_col = col_map['uph']

    mean = df[uph_col].mean()
    std = df[uph_col].std()
    if std == 0:
        return df  # ‡∏ñ‡πâ‡∏≤ std = 0, return ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°
    z_scores = (df[uph_col] - mean) / std
    filtered = df[(z_scores >= -3) & (z_scores <= 3)].copy()
    filtered['Outlier_Method'] = 'Z-Score ¬±3'
    return filtered

def has_outlier(df):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ outliers ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ IQR"""
    col_map = {col.lower(): col for col in df.columns}
    if 'uph' not in col_map:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå UPH ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    uph_col = col_map['uph']

    Q1 = df[uph_col].quantile(0.25)
    Q3 = df[uph_col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return ((df[uph_col] < lower) | (df[uph_col] > upper)).sum() > 0

def apply_iqr(df):
    """‡∏ï‡∏±‡∏î outliers ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ IQR (Interquartile Range)"""
    col_map = {col.lower(): col for col in df.columns}
    if 'uph' not in col_map:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå UPH ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    uph_col = col_map['uph']

    Q1 = df[uph_col].quantile(0.25)
    Q3 = df[uph_col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    filtered = df[(df[uph_col] >= lower) & (df[uph_col] <= upper)].copy()
    filtered['Outlier_Method'] = 'IQR'
    return filtered

def remove_outliers_auto(df_model, max_iter=20):
    """‡∏ï‡∏±‡∏î outliers ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Z-Score ‡πÅ‡∏•‡∏∞ IQR ‡πÅ‡∏ö‡∏ö‡∏ß‡∏ô‡∏•‡∏π‡∏õ"""
    col_map = {col.lower(): col for col in df_model.columns}
    if 'uph' not in col_map:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå UPH ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    uph_col = col_map['uph']

    df_model[uph_col] = pd.to_numeric(df_model[uph_col], errors='coerce')
    df_model = df_model.dropna(subset=[uph_col])

    if len(df_model) < 15:  
        df_model['Outlier_Method'] = '‡πÑ‡∏°‡πà‡∏ï‡∏±‡∏î (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢)'
        return df_model

    current_df = df_model.copy()

    for i in range(max_iter):
        print(f"=== ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà {i+1} ===")
        z_df = apply_zscore(current_df)
        if not has_outlier(z_df):
            z_df['Outlier_Method'] = f'Z-Score Loop √ó{i+1}'
            return z_df

        iqr_df = apply_iqr(z_df)
        if not has_outlier(iqr_df):
            iqr_df['Outlier_Method'] = f'IQR Loop √ó{i+1}'
            return iqr_df

        current_df = iqr_df

    current_df['Outlier_Method'] = f'IQR-Z-Score Loop √ó{max_iter}+'
    return current_df

def remove_outliers(df):
    """‡∏ï‡∏±‡∏î outliers ‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏° BOM ‡πÅ‡∏•‡∏∞ Machine Model"""
    col_map = {col.lower(): col for col in df.columns}
    
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Machine Model
    model_col = None
    if 'machine model' in col_map:
        model_col = col_map['machine model']
    elif 'machine_model' in col_map:
        model_col = col_map['machine_model']
    else:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Machine Model ‡∏´‡∏£‡∏∑‡∏≠ Machine_Model ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå bom_no
    bom_col = None
    if 'bom_no' in col_map:
        bom_col = col_map['bom_no']
    elif 'bom no' in col_map:
        bom_col = col_map['bom no']
    else:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå bom_no ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î outliers ‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏° bom_no ‡πÅ‡∏•‡∏∞ Machine Model
    result_dfs = []
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° bom_no ‡πÅ‡∏•‡∏∞ Machine Model
    for (bom_no, machine_model), group_df in df.groupby([bom_col, model_col]):
        print(f"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Å‡∏•‡∏∏‡πà‡∏°: BOM={bom_no}, Machine={machine_model}, ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•={len(group_df)}")
        
        # ‡∏ï‡∏±‡∏î outliers ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Å‡∏•‡∏∏‡πà‡∏°
        cleaned_group = remove_outliers_auto(group_df)
        result_dfs.append(cleaned_group)
    
    # ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    return pd.concat(result_dfs, ignore_index=True)

def time_series_analysis(df):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ"""
    col_map = {col.lower(): col for col in df.columns}
    
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ
    date_cols = []
    for col_name in df.columns:
        if any(keyword in col_name.lower() for keyword in ['date', 'time', '‡∏ß‡∏±‡∏ô', '‡πÄ‡∏ß‡∏•‡∏≤']):
            date_cols.append(col_name)
    
    if not date_cols:
        print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        return df
    
    # ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏û‡∏ö
    date_col = date_cols[0]
    print(f"‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {date_col}")
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô datetime ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
    df['date_time_start'] = pd.to_datetime(df[date_col], errors='coerce')
    
    # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏õ‡πá‡∏ô YYYY/MM/DD
    df['date_time_start'] = df['date_time_start'].dt.strftime('%Y/%m/%d')
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
    invalid_dates = df['date_time_start'].isna().sum()
    if invalid_dates > 0:
        print(f"‡∏û‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {invalid_dates} ‡πÅ‡∏ñ‡∏ß")
        df = df.dropna(subset=['date_time_start'])
    
    print(f"‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: {df['date_time_start'].iloc[0] if len(df) > 0 else '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•'}")
    
    return df
    
def find_max_or_min_date(df):
    if 'date_time_start' not in df.columns:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå date_time_start ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

    max_date = df['date_time_start'].max()
    min_date = df['date_time_start'].min()
    return max_date, min_date

def get_date_range_auto(df):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)"""
    max_date, min_date = find_max_or_min_date(df)
    print(f"‡πÉ‡∏ä‡πâ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {min_date} ‡∏ñ‡∏∂‡∏á {max_date}")
    return min_date, max_date

def filter_data_by_date(df, start_date, end_date):
    """‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"""
    print(f"\n=== ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà {start_date} ‡∏ñ‡∏∂‡∏á {end_date} ===")
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    filtered_df = df[df['date_time_start'].between(start_date, end_date)].copy()
    
    if len(filtered_df) == 0:
        print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
        return None
    
    print(f"‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(filtered_df)} ‡πÅ‡∏ñ‡∏ß ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°: {len(df)} ‡πÅ‡∏ñ‡∏ß")
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á: {len(filtered_df)} ‡πÅ‡∏ñ‡∏ß ({len(filtered_df)/len(df)*100:.1f}%)")
    
    return filtered_df

def calculate_group_average(df, start_date, end_date):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°"""
    col_map = {col.lower(): col for col in df.columns}
    
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Machine Model
    model_col = None
    if 'machine model' in col_map:
        model_col = col_map['machine model']
    elif 'machine_model' in col_map:
        model_col = col_map['machine_model']
    else:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Machine Model ‡∏´‡∏£‡∏∑‡∏≠ Machine_Model ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå bom_no
    bom_col = None
    if 'bom_no' in col_map:
        bom_col = col_map['bom_no']
    elif 'bom no' in col_map:
        bom_col = col_map['bom no']
    else:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå bom_no ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå UPH
    uph_col = None
    if 'uph' in col_map:
        uph_col = col_map['uph']
    else:
        raise KeyError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå UPH ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°
    grouped_average = df.groupby([bom_col, model_col])[uph_col].mean().reset_index()
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    print(f"\n=== ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ UPH ‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏° (‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà {start_date} ‡∏ñ‡∏∂‡∏á {end_date}) ===")
    print(grouped_average)
    
    return grouped_average

def save_results(df_cleaned, grouped_average, start_date, end_date, output_dir):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå"""
    os.makedirs(output_dir, exist_ok=True)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    date_range = f"{start_date.replace('/', '')}_to_{end_date.replace('/', '')}"
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î outliers ‡πÅ‡∏•‡πâ‡∏ß
    cleaned_file = os.path.join(output_dir, f"cleaned_data_{date_range}_{timestamp}.xlsx")
    df_cleaned.to_excel(cleaned_file, index=False)
    print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î outliers ‡πÅ‡∏•‡πâ‡∏ß: {cleaned_file}")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°
    average_file = os.path.join(output_dir, f"group_average_{date_range}_{timestamp}.xlsx")
    grouped_average.to_excel(average_file, index=False)
    print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°: {average_file}")
    
    return cleaned_file, average_file

def process_die_attack_data(file_path):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Die Attack"""
    print("=== ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Die Attack ===")
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    try:
        df = pd.read_excel(file_path)
        print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: {len(df)} ‡πÅ‡∏ñ‡∏ß")
    except Exception as e:
        raise Exception(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ: {str(e)}")
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    print("\n1. ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà...")
    df = time_series_analysis(df)
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÉ‡∏ä‡πâ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
    print("\n2. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà...")
    start_date, end_date = get_date_range_auto(df)
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    print("\n3. ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà...")
    df_filtered = filter_data_by_date(df, start_date, end_date)
    
    if df_filtered is None:
        raise Exception("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏ï‡∏±‡∏î outliers
    print("\n4. ‡∏ï‡∏±‡∏î outliers...")
    df_cleaned = remove_outliers(df_filtered)
    df_cleaned = df_cleaned.reset_index(drop=True)
    
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏±‡∏î outliers: {len(df_cleaned)} ‡πÅ‡∏ñ‡∏ß")
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°
    print("\n5. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°...")
    grouped_average = calculate_group_average(df_cleaned, start_date, end_date)
    
    print("\n=== ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ===")
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: {len(df_cleaned)} ‡πÅ‡∏ñ‡∏ß")
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°: {len(grouped_average)} ‡∏Å‡∏•‡∏∏‡πà‡∏°")
    
    return df_cleaned, grouped_average, start_date, end_date

def process_die_attack_data_with_date_range(file_path, start_date, end_date):
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Die Attack ‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î"""
    print("=== ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Die Attack (‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î) ===")
    
    # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    try:
        df = pd.read_excel(file_path)
        print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: {len(df)} ‡πÅ‡∏ñ‡∏ß")
    except Exception as e:
        raise Exception(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ: {str(e)}")
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    print("\n1. ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà...")
    df = time_series_analysis(df)
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å YYYY-MM-DD ‡πÄ‡∏õ‡πá‡∏ô YYYY/MM/DD
    print(f"\n2. ‡πÉ‡∏ä‡πâ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î: {start_date} ‡∏ñ‡∏∂‡∏á {end_date}")
    formatted_start_date = start_date.replace('-', '/')
    formatted_end_date = end_date.replace('-', '/')
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
    print("\n3. ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà...")
    df_filtered = filter_data_by_date(df, formatted_start_date, formatted_end_date)
    
    if df_filtered is None:
        raise Exception("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏ï‡∏±‡∏î outliers
    print("\n4. ‡∏ï‡∏±‡∏î outliers...")
    df_cleaned = remove_outliers(df_filtered)
    df_cleaned = df_cleaned.reset_index(drop=True)
    
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏±‡∏î outliers: {len(df_cleaned)} ‡πÅ‡∏ñ‡∏ß")
    
    # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°
    print("\n5. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°...")
    grouped_average = calculate_group_average(df_cleaned, formatted_start_date, formatted_end_date)
    
    print("\n=== ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ===")
    print(f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢: {len(df_cleaned)} ‡πÅ‡∏ñ‡∏ß")
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°: {len(grouped_average)} ‡∏Å‡∏•‡∏∏‡πà‡∏°")
    
    return df_cleaned, grouped_average, formatted_start_date, formatted_end_date

def preview_date_range(file_path):
    """‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"""
    try:
        print("üìÖ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå...")
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        df = pd.read_excel(file_path)
        print(f"üìÑ ‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df):,} ‡πÅ‡∏ñ‡∏ß")
        
        # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        date_cols = []
        for col_name in df.columns:
            if any(keyword in col_name.lower() for keyword in ['date', 'time', '‡∏ß‡∏±‡∏ô', '‡πÄ‡∏ß‡∏•‡∏≤']):
                date_cols.append(col_name)
        
        if not date_cols:
            print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            return None
        
        date_col = date_cols[0]
        print(f"üóìÔ∏è ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: '{date_col}'")
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        df['temp_date'] = pd.to_datetime(df[date_col], errors='coerce')
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ
        valid_dates = df.dropna(subset=['temp_date'])
        invalid_count = len(df) - len(valid_dates)
        
        if len(valid_dates) == 0:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå")
            return None
        
        # ‡∏´‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î
        min_date = valid_dates['temp_date'].min()
        max_date = valid_dates['temp_date'].max()
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        print(f"\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà:")
        print(f"  üóìÔ∏è ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: {min_date.strftime('%Y-%m-%d')} (‡∏Ñ.‡∏®.)")
        print(f"  üóìÔ∏è ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î: {max_date.strftime('%Y-%m-%d')} (‡∏Ñ.‡∏®.)")
        print(f"  üìà ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô: {(max_date - min_date).days + 1} ‡∏ß‡∏±‡∏ô")
        print(f"  ‚úÖ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {len(valid_dates):,} ‡πÅ‡∏ñ‡∏ß")
        
        if invalid_count > 0:
            print(f"  ‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {invalid_count:,} ‡πÅ‡∏ñ‡∏ß")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤
        print(f"\nüìã ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô:")
        monthly_counts = valid_dates.groupby(valid_dates['temp_date'].dt.to_period('M')).size()
        for period, count in monthly_counts.head(10).items():
            print(f"  üìÖ {period}: {count:,} ‡πÅ‡∏ñ‡∏ß")
        
        if len(monthly_counts) > 10:
            print(f"  ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(monthly_counts) - 10} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
        
        return {
            'min_date': min_date.strftime('%Y-%m-%d'),
            'max_date': max_date.strftime('%Y-%m-%d'),
            'total_days': (max_date - min_date).days + 1,
            'valid_records': len(valid_dates),
            'invalid_records': invalid_count,
            'date_column': date_col,
            'monthly_distribution': {str(period): count for period, count in monthly_counts.to_dict().items()}
        }
        
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {str(e)}")
        return None

def run(input_dir, output_dir, start_date=None, end_date=None, use_all_dates=True):

    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Die Attack Auto UPH")
    print(f"üìÅ Input directory: {input_dir}")
    print(f"üìÅ Output directory: {output_dir}")
    
    if not use_all_dates and start_date and end_date:
        print(f"üìÖ ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {start_date} ‡∏ñ‡∏∂‡∏á {end_date}")
    else:
        print("üìÖ ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
    
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå input ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not os.path.exists(input_dir):
            raise Exception(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå input: {input_dir}")
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Excel ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå input
        excel_files = []
        for file in os.listdir(input_dir):
            if file.lower().endswith(('.xlsx', '.xls')):
                excel_files.append(os.path.join(input_dir, file))
        
        if not excel_files:
            raise Exception("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Excel ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå input")
        
        # ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏û‡∏ö
        input_file = excel_files[0]
        print(f"üìÑ ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå: {os.path.basename(input_file)}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        print(f"\n" + "="*50)
        print("üîç ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå")
        print("="*50)
        
        date_info = preview_date_range(input_file)
        
        if date_info:
            print(f"\nüí° ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:")
            print(f"  ‚Ä¢ ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å '‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î'")
            print(f"  ‚Ä¢ ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á {date_info['min_date']} ‡∏ñ‡∏∂‡∏á {date_info['max_date']}")
        
        print(f"\n" + "="*50)
        print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        print("="*50)
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà
        if use_all_dates:
            df_cleaned, grouped_average, actual_start_date, actual_end_date = process_die_attack_data(input_file)
        else:
            df_cleaned, grouped_average, actual_start_date, actual_end_date = process_die_attack_data_with_date_range(
                input_file, start_date, end_date
            )
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        cleaned_file, average_file = save_results(
            df_cleaned, grouped_average, actual_start_date, actual_end_date, output_dir
        )
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ
        summary = {
            'input_file': os.path.basename(input_file),
            'cleaned_file': os.path.basename(cleaned_file),
            'average_file': os.path.basename(average_file),
            'total_records': len(df_cleaned),
            'groups_count': len(grouped_average),
            'date_range': f"{actual_start_date} ‡∏ñ‡∏∂‡∏á {actual_end_date}",
            'use_all_dates': use_all_dates,
            'processing_date_range': {
                'start': actual_start_date,
                'end': actual_end_date,
                'user_defined': not use_all_dates
            },
            'file_date_info': date_info,  # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
            'status': 'success'
        }
        
        print(f"\n‚úÖ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
        print(f"üìä ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î outliers: {os.path.basename(cleaned_file)}")
        print(f"üìà ‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°: {os.path.basename(average_file)}")
        print(f"üìã ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(df_cleaned):,} ‡πÅ‡∏ñ‡∏ß")
        print(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°: {len(grouped_average)} ‡∏Å‡∏•‡∏∏‡πà‡∏°")
        
        return summary
        
    except Exception as e:
        error_msg = f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"
        print(error_msg)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
        error_summary = {
            'status': 'error',
            'error_message': str(e),
            'input_dir': input_dir,
            'output_dir': output_dir
        }
        
        return error_summary

